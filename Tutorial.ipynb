{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebooks for Teaching Neuroscience\n",
    "\n",
    "Welcome! In this notebook, we'll explore how to use Jupyter to run Python code, a few examples of simple demonstrations using this code, and some analysis of open access data available via the Allen Institute for Brain Science.\n",
    "\n",
    "### At the end of this notebook, you'll be able to:\n",
    "* Recognize the main features of Jupyter Notebooks\n",
    "* Edit and run code and markdown cells\n",
    "* Run simple statistics and signal processing demonstrations\n",
    "* Analyze data from the Allen Institute for Brain Science\n",
    "\n",
    "### Table of Contents\n",
    "[About Jupyter Notebooks](#about)\n",
    "\n",
    "Three demonstrations of how one might use this type of notebook:\n",
    "1. [Teaching Statistics](#one)\n",
    "2. [Signal Processing](#two)\n",
    "3. [Neural Data Science](#three)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before we dive in, let's get this cell running. This cell will download the necessary components for working with the Allen Cell Types datasets below.\n",
    "\n",
    "Run the cell below by clicking on it, and choosing the \"Run\" button above. Alternatively, you can press \"shift + enter.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is going to check to make sure you have the necessary packages.\n",
    "try:\n",
    "    import allensdk\n",
    "except ImportError as e:\n",
    "    !pip install allensdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we also need to import packages to use. Below, we'll import several common packages for scientific computing: `numpy`, `pandas`, `scipy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our necessary toolboxes and tell matplotlib to plot inline\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print('Packages imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "## About Jupyter Notebooks\n",
    "\n",
    "Jupyter notebooks are a way to combine executable code, code outputs, and text into one connected file. They run in a web browser, but don't require the internet (unless you're running it on a Jupyter Hub). \n",
    "\n",
    "The <b>'kernel'</b> is the thing that executes your code. It is what connects the notebook (as you see it) with the part of your computer, or the DataHub computers, that runs code.\n",
    "\n",
    "### Menu Options & Shortcuts\n",
    "To get a quick tour of the Jupyter user-interface, click on the 'Help' menu, then click 'User Interface Tour'. There are also a large number of useful keyboard shortcuts. Click on the 'Help' menu, and then 'Keyboard Shortcuts' to see a list.\n",
    "\n",
    "\n",
    "### Types of Cells\n",
    "Jupyter Notebooks have two types of cells, a <b>Markdown</b> (like this one) and <b>Code</b>. Most of the time you won't need to run the Markdown cells, just read through them. However, when we get to a code cell, you need to tell Jupyter to run the lines of code that it contains.\n",
    "\n",
    "Code cells will be read by the Python interpreter. In other words, the Python kernel will run whatever it recognizes as code within the cell.\n",
    "\n",
    "<span style=\"color:blue\">When you're in <b>Command mode</b>, cells are outlined in blue</span>. <span style=\"color:green\">When you're in <b>Edit mode</b>, blocks are outlined in green</span>.\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task:</b> Run the cell below!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In Python, anything with a \"#\" in front of it is code annotation,\n",
    "# and is not read by the computer.\n",
    "# You can run a cell (this box) by pressing shift-enter.\n",
    "# Click in this cell and then press shift and enter simultaneously.\n",
    "# This print function below allows us to generate a message.\n",
    "print('Nice work!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables** enable us to store a value and come back to it later. They are defined with the syntax `name = value`.\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task:</b> Create two variables: <code>a</code> & <code>b</code>. Then, use an expression that combines <code>a</code> and <code>b</code>, and assign this to a new variable, <code>c</code>. In the end, <code>c</code> should be equal to 6.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Markdown\n",
    "Markdown is useful because it can be formatted using simple symbols.\n",
    "* You can create bulleted lists using asterisks.\n",
    "* Similarly, you can create numbered lists using numbers.\n",
    "* You can **bold** with two asterisks or underscores on either side (`**bold**`) or *italicize* with one asterisk or underscore (`*italicize*`)\n",
    "* Pound signs (#) create headers. More pound signs means a smaller header.\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task:</b> Edit the markdown cell below with a quick biography of yourself. You should have your name as a big header, a short quippy subtitle for yourself as a smaller header, and a three bullet points that use both <b>bold</b> and <i>italic</i>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your markdown here! Double click to edit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## Demo #1: Teaching Statistics\n",
    "\n",
    "Notebooks like these can be useful for teaching statistical concepts, such as characterizing and describing distributions, hypothesis testing and the central limit theorem. Let's take a look at a way to test whether or not [the central limit theorem's depends on underlying distribution types](https://www.nature.com/articles/nmeth.2613)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on some parameters for our demonstration\n",
    "sample_sizes = [3,9,27,81,243]\n",
    "distribution_type = 'normal' # 'normal','skewed', or 'uniform'\n",
    "mu = 0 # for the normal distribution\n",
    "sigma = 10 # for the normal distribution\n",
    "print('Parameters set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're going to be generating distributions below based on our preferences, let's build a **function** to do this for us. We'll also take a look at what one of these distributions looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDistribution(distribution_type,mu,sigma,sample_size):\n",
    "    if distribution_type == 'normal':\n",
    "        sample_dist = np.random.normal(mu, sigma, sample_size) # Create a normal distribution with mu, sigma\n",
    "    elif distribution_type == 'skewed':\n",
    "        sample_dist = np.random.gamma(7.5,1,sample_size) # Create a skewed gamma distribution\n",
    "    elif distribution_type == 'uniform':\n",
    "        sample_dist = np.random.random_sample(sample_size)*20 # Create a uniform distribution\n",
    "    return sample_dist\n",
    "\n",
    "# Use our function to create a distribution\n",
    "sample_dist = createDistribution(distribution_type,mu,sigma,sample_size=100)\n",
    "\n",
    "# Plot our sample distribution\n",
    "plt.hist(sample_dist)\n",
    "plt.ylabel('# Observations')\n",
    "plt.xlabel('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up our parameters, let's demonstrate that the CLT is true regardless of the underlying distribution type. We'll also see that the increase in precision of our estimate of the population mean increases with sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "fig,ax = plt.subplots(1,5,figsize=(20,5),sharey=True)\n",
    "\n",
    "sample_means = []\n",
    "\n",
    "# For each subplot, create a plot.\n",
    "for i in range(len(ax)):\n",
    "    \n",
    "    # Make the sample size = to 3^(a+1)\n",
    "    sample_size = sample_sizes[i]\n",
    "    \n",
    "    # Calculate the mean of sample of sample_size designated above, 1000 times\n",
    "    for x in range(1000):\n",
    "        sample_dist = createDistribution(distribution_type,mu,sigma,sample_size) # Use our function above\n",
    "        sample_means.append(np.mean(sample_dist)) # Append the mean of this distribution\n",
    "        \n",
    "    ax[i].hist(sample_means,color='teal',alpha = .5) # Plot the distribution of means\n",
    "    ax[i].set_title('sample size= '+ str(sample_size)+', mean = '+ str(np.round(np.mean(sample_means),3)))\n",
    "    ax[i].set_xlim([-20,20])\n",
    "    sample_means = [] # Reset the sample means\n",
    "\n",
    "plt.suptitle('Distributions of 10,000 sample means for a ' + distribution_type + ' distribution',fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about other things you could simulate, including statistical tests? See an example notebook [here](https://github.com/BIPN162/Materials/blob/master/11-Statistics_solutions.ipynb).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## Demo #2: Signal processing\n",
    "\n",
    "Let's first generate a sine wave. We'll then generate a second sine wave and add these together to understand what a fourier transform of this data would look like. **Sine waves** are defined by their frequency, ampltitude, and and phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 1024 # Sampling frequency\n",
    "duration = 0.3 # 0.3 seconds of signal\n",
    "freq1 = 7 # 7 Hz signal\n",
    "freq2 = 130 # 130 Hz signal\n",
    "\n",
    "time_vector = np.arange(0, duration, 1/sampling_freq) # Generate a time vector\n",
    "\n",
    "signal_1 = np.sin(2 * np.pi * freq1 * time_vector)     # Generate a sine wave\n",
    "signal_2 = np.sin(2 * np.pi * freq2 * time_vector) * 2 # Generate another sine wave, with double the power\n",
    "# Add the signals we created above into one signal\n",
    "combined_signal = signal_1 + signal_2\n",
    "\n",
    "print('You\\'ve created a complex signal with two sin waves, it looks like this:')\n",
    "print(combined_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps plotting the signal would be good, eh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.plot(time_vector,signal_1+signal_2) #plot 0.5 seconds of data\n",
    "plt.ylabel('Signal',fontsize=14)\n",
    "plt.xlabel('Time',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll calculate the **Fourier Transform**, which will determine the frequencies that are in our sample. We'll implement this with [**Welch's Method**](https://en.wikipedia.org/wiki/Welch%27s_method), which consists in averaging consecutive Fourier transform of small windows of the signal, with or without overlapping. Basically, we calculate the fourier transform of a signal across a few sliding windows, and then calculate the mean PSD from all the sliding windows.\n",
    "\n",
    "The `freqs` vector contains the x-axis (frequency bins) and the `psd` vector contains the y-axis values (power spectral density). The units of the power spectral density, when working with EEG data, is usually $\\mu$V^2 per Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import our signal processing package\n",
    "from scipy import signal\n",
    "\n",
    "# Define sliding window length (4 seconds, which will give us 2 full cycles at 0.5 Hz)\n",
    "win = 4 * sampling_freq\n",
    "freqs, psd = signal.welch(combined_signal, sampling_freq, nperseg=win)\n",
    "\n",
    "# Plot our data\n",
    "plt.plot(freqs,psd) # Plot a select range of frequencies\n",
    "plt.ylabel('Power')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.title('FFT of a complex signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing real sleep EEG Data\n",
    "\n",
    "Normal physiological data is never as regular as the data above -- it's usually chock full of lots of different waves, as well as noise. Now that we have a sense of the tools we need, let's work with some real data.\n",
    "\n",
    "The data we'll import here is a real 30-seconds extract of slow-wave sleep from a young individual, collected by the Walker Lab at UC Berkeley. This data was collected at 100 Hz from channel 'F3'. This sampling frequency is fine for EEG data, but wouldn't be enough for high frequency spiking data. That kind of data is typically sampled at 40 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URL of data to download\n",
    "data_url = 'https://raphaelvallat.com/images/tutorials/bandpower/data.txt'\n",
    "\n",
    "# Get the data and save it locally as \"sleep_data.txt\"\n",
    "sleep_data, headers = urllib.request.urlretrieve(data_url, './sleep_data.txt')\n",
    "\n",
    "# Load the .txt file as a numpy array\n",
    "data = np.loadtxt('sleep_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, let's took a look at the raw signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define sampling frequency and time vector, because this data is in samples, not timestamps\n",
    "sampling_freq = 100 # sampling frequency\n",
    "num_samples = len(data) # number of samples\n",
    "time_vector = np.arange(num_samples) / sampling_freq # create a time vector\n",
    "\n",
    "# Plot the signal\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.plot(time_vector, data)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.title('N3 sleep EEG data (F3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this real EEG data, the underlying frequencies are much harder to see by eye. So, we'll run a fourier transform (via Welch's method) on our data to put this into the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sliding window length (4 seconds, which will give us 2 full cycles at 0.5 Hz)\n",
    "win = 4 * sampling_freq\n",
    "freqs, psd = signal.welch(data, sampling_freq, nperseg=win)\n",
    "\n",
    "# Plot the power spectrum\n",
    "plt.plot(freqs, psd)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power spectral density (V^2 / Hz)')\n",
    "plt.xlim([0, 10]) # Uncomment this to restrict the x-axis so that we can zoom in\n",
    "plt.title(\"Welch's PSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, there is plenty of delta activity here (from 0.5 to 4 Hz)!\n",
    "\n",
    "For additional ideas on how to incorporate signal processing into a Jupyter Notebook, see [this notebook](https://github.com/BIPN162/Materials_Solutions/blob/master/15-SignalProcessing_solutions.ipynb).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## Neural Data Science\n",
    "As a final demonstration, we'll look at electrophysiology data from the Allen Institute's [Cell Types Atlas](https://celltypes.brain-map.org/). This is just one of many incredible [datasets](https://portal.brain-map.org/) available from the Allen Institute for Brain Science.\n",
    "\n",
    "**Note**: If you run the cell below and receive an error related to pandas and, create a new cell and run `!pip install pandas==0.23.4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary toolboxes from the AllenSDK\n",
    "from allensdk.core.cell_types_cache import CellTypesCache\n",
    "from allensdk.api.queries.cell_types_api import CellTypesApi\n",
    "\n",
    "# We'll then initialize the cache as 'ctc' (cell types cache)\n",
    "ctc = CellTypesCache(manifest_file='cell_types/manifest.json')\n",
    "\n",
    "# Get the human metadata, turn it into a dataframe, and set the index to be ID\n",
    "# In this line, you can also specify a specific cre line, or experiment.\n",
    "human_df = pd.DataFrame(ctc.get_cells(species=[CellTypesApi.HUMAN])).set_index('id')\n",
    "\n",
    "# Get the ephys data, turn it into a dataframe, and set the index to be specimen ID\n",
    "ephys_features = pd.DataFrame(ctc.get_ephys_features()).set_index('specimen_id')\n",
    "\n",
    "# Join the two dataframes\n",
    "human_ephys_df = human_df.join(ephys_features)\n",
    "\n",
    "# Show the first 5 rows\n",
    "human_ephys_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, let's plot two of the features in our dataset:\n",
    "- **Action potential fast trough** (`fast_trough_v_long_square`): Minimum value of the membrane potential in the interval lasting 5 ms after the peak.\n",
    "- **Upstroke/downstroke ratio** (`upstroke_downstroke_ratio_long_square`): The ratio between the absolute values of the action potential peak upstroke and the action potential peak downstroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(human_ephys_df['fast_trough_v_long_square'], \n",
    "            human_ephys_df['upstroke_downstroke_ratio_long_square'])\n",
    "plt.ylabel(\"upstroke-downstroke ratio\")\n",
    "plt.xlabel(\"fast trough depth (mV)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there may be roughly two clusters in the data above. Maybe they relate to whether the cells are presumably **excitatory (spiny)** cells or **inhibitory (aspiny)** cells. Let's color our dots by their dendrite type!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible dendrite types\n",
    "dendrite_types = human_ephys_df['dendrite_type'].unique()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for d_type in dendrite_types:\n",
    "    \n",
    "    df = human_ephys_df[human_ephys_df['dendrite_type'] == d_type]\n",
    "    \n",
    "    plt.scatter(df['fast_trough_v_long_square'], \n",
    "                df['upstroke_downstroke_ratio_long_square'],\n",
    "                label=d_type)\n",
    "    \n",
    "plt.ylabel(\"upstroke-downstroke ratio\")\n",
    "plt.xlabel(\"fast trough depth (mV)\")\n",
    "plt.legend(loc='best') \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells with spiny dendrites (which are typically excitatory cells) have a big ratio of upstroke:downstroke, and a more shallow trough (less negative). Cells with aspiny dendrites (typically inhibitory cells) are a little bit more varied. But </i>only</i> aspiny cells have a low upstroke:downstroke ratio and a deeper trough (more negative).\n",
    "\n",
    "More discoveries abound! For a full notebook explaining how to interact with the Cell Types dataset, see [this repository](https://github.com/ajuavinett/CellTypesLesson). For additional ideas about how to work with the Allen Institute data in your classes, see [this website](https://sites.google.com/ucsd.edu/neuroedu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celebrate\n",
    "That's the **Teaching with Jupyter Notebooks tutorial**! Go forth and share :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"https://media1.tenor.com/images/f708e56b6ab99de21228c95203c7af8e/tenor.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "For additional Jupyter Notebook information and practice, see [this tutorial](https://www.dataquest.io/blog/jupyter-notebook-tutorial/) from DataQuest. \n",
    "\n",
    "## About this Notebook\n",
    "This notebook was created by [Ashley Juavinett](https://github.com/ajuavinett) for a workshop during the Faculty for Undergraduate Neuroscience Summer Virtual Meeting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
